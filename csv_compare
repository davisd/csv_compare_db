#!/usr/bin/env python2

import csv
import sys
import os
import argparse

def compare(file1, file2, id_column, conn, table_name):
    """
    Compare two csv files

    file1 - The first file
    file2 - The second file
    id_column - The name of the column containing the unique ID
    conn - Established database connection
    table_name -- Name of the db table to create for matching
    """
    # get a couple of csv readers from the files
    f1=open(file1, 'rb')
    csv1=csv.reader(f1)
    header1=csv1.next()

    f2=open(file2, 'rb')
    csv2=csv.reader(f2)
    header2=csv2.next()

    if (header1 != header2):
        raise Exception ('The header rows do not match')

    if id_column not in header1:
        raise Exception('The id coumn does not exist')

    id_column_index=header1.index(id_column)

    # get our first cursor
    c=conn.cursor()

    # Create the comparison table
    c.execute('create table %s (hashed_id int, id text, file_id integer, line_number integer, ' \
        'hashed integer, csv text)' % (table_name, ))

    # Create indexes
    c.execute('create index hashed_id_index on %s (hashed_id)' \
        % (table_name,))

    # Create indexes
    c.execute('create index file_id_index on %s (file_id)' \
        % (table_name,))

    # Create indexes
    c.execute('create index hashed_index on %s (hashed)' \
        % (table_name,))

    # read the data into the table

    row_count=1
    for row in csv1:
        row_count+=1
        csv_text=unicode(','.join(row), encoding='utf-8').replace("'", "''")
        sql="""insert into %s (hashed_id, id, file_id, line_number, hashed, csv) values (%d, '%s', 1, %d, %d, '%s')""" % \
            (table_name, hash(row[id_column_index]), row[id_column_index], row_count, hash(csv_text), csv_text)

        c.execute(sql)

    row_count=1
    for row in csv2:
        row_count+=1
        csv_text=unicode(','.join(row), encoding='utf-8').replace("'", "''")
        sql="""insert into %s (hashed_id, id, file_id, line_number, hashed, csv) values (%d, '%s', 2, %d, %d, '%s')""" % \
            (table_name, hash(row[id_column_index]), row[id_column_index], row_count, hash(csv_text), csv_text)
        c.execute(sql)

    conn.commit();

    c.close()
    c=conn.cursor()

    # Find duplicate rows within the same files
    c.execute(
    """ select id from %(table_name)s
        where file_id=1
        and hashed_id in
            (select hashed_id from %(table_name)s
            where file_id=1 GROUP BY id
            having (COUNT(id) > 1))
    """ % {'table_name': table_name})

    nonunique_ids=False

    first_iteration=True
    for row in c:
        if first_iteration:
            first_iteration=False
            sys.stderr.write('Duplicate IDs in %s \n' % (file1,))
            nonunique_ids=True
        sys.stderr.write('%s\n' % (row[0],))

    c.close()
    c=conn.cursor()

    c.execute(
    """ select id from %(table_name)s
        where file_id=2
        and hashed_id in
            (select hashed_id from %(table_name)s
            where file_id=2 GROUP BY id
            having (COUNT(id) > 1))
    """ % {'table_name': table_name})

    first_iteration=True
    for row in c:
        if first_iteration:
            first_iteration=False
            sys.stderr.write('Duplicate IDs in %s \n' % (file2,))
            nonunique_ids=True
        sys.stderr.write('%s\n' % (row[0],))

    c.close()
    c=conn.cursor()

    if nonunique_ids:
        raise Exception('There are non-unique IDs in the individual files. ' \
            'Cannot continue')

    c.close()
    c=conn.cursor()

    # Find rows in file 1, not in file 2
    c.execute(
    """ select id from %(table_name)s
        where file_id=1
        and hashed_id not in
            (select hashed_id from %(table_name)s
            where file_id=2)
    """ % {'table_name': table_name})

    first_iteration=True
    for row in c:
        if first_iteration:
            first_iteration=False
            sys.stderr.write('IDs in %s and NOT in %s:\n' % (file1,file2))
        sys.stderr.write('%s\n' % (row[0]))

    c.close()
    c=conn.cursor()

    # Find rows in file 2, not in file 1
    c.execute(
    """ select id from %(table_name)s
        where file_id=2
        and hashed_id not in
            (select hashed_id from %(table_name)s
            where file_id=1)
    """ % {'table_name': table_name})

    first_iteration=True
    for row in c:
        if first_iteration:
            first_iteration=False
            sys.stderr.write('IDs in %s and NOT in %s:\n' % (file2,file1))
        sys.stderr.write('%s\n' % (row[0]))

    c.close()
    c=conn.cursor()


    ## Find rows where the IDs match, the File IDs do not, and the Hashes do not
    #c.execute(
    #""" select c1.csv, c2.csv from
    #        %(table_name)s as c1, %(table_name)s as c2
    #    where c1.id=c2.id
    #    and c1.file_id=1 and c2.file_id=2
    #    and c1.hashed!=c2.hashed
    #""" % {'table_name': table_name})

    # Find rows where the IDs match, the File IDs do not, and the Hashes do not
    c.execute(
    """ select c1.csv, c2.csv from %(table_name)s as c1, %(table_name)s as c2

        where c1.file_id!=c2.file_id

        -- and c1.hashed_id in
        --   (select hashed_id from %(table_name)s where file_id=2)

        and c1.hashed_id = c2.hashed_id
        and c1.hashed != c2.hashed
        and c1.id = c2.id
    """ % {'table_name': table_name})

    first_iteration=True
    for row in c:
        if first_iteration:
            first_iteration=False
            sys.stderr.write('Writing mismatched results to stdout\n')
            sys.stdout.write('%s\n' % (','.join(header1)),)
        sys.stdout.write('%s\n' % (row[0],))
        sys.stdout.write('%s\n' % (row[1],))

    # close the connections
    c.close()
    conn.close()

def get_db_connection(db_type, database):
    try:
        db_handler=__import__(db_type)

        if db_type[:6] == 'sqlite':
            if database != ':memory:' and os.path.exists(database):
                raise argparse.ArgumentTypeError('database file %s already ' \
                    'exists' % (database,))

        return db_handler.connect(database)

    except ImportError:
        raise argparse.ArgumentTypeError('Error importing %s module. Make ' \
                'sure that you have this Python database module installed, ' \
                'you have spelled it correectly, and that you have the ' \
                'module on your Python path.' \
            % (db_type,))

def main(argv=None):
    if argv is None:
        argv = sys.argv

    parser=argparse.ArgumentParser(description='compare two csv files')
    parser.add_argument('file1', help='first file')
    parser.add_argument('file2', help='second file')
    parser.add_argument('identity_col', metavar='identity column',
        help='identity column name')

    parser.add_argument('-t', '--db-type', help='Database python module',
            default='sqlite3')

    parser.add_argument('-d', '--database', metavar='db',
            default=':memory:',
            help='database connection string. For sqlite3, :memory: is a ' \
                'special type and will cause no file to be created.')

    parser.add_argument('-n', '--table-name', help='Database table name for ' \
            'comparison operations',
            default='__cmp')

    args=parser.parse_args(argv[1:])

    file1=args.file1
    file2=args.file2
    identity_col=args.identity_col
    db_type=args.db_type
    database=args.database
    table_name=args.table_name

    # get a connection
    conn=get_db_connection(db_type, database)

    compare(file1, file2, identity_col, conn, table_name)

if __name__ == "__main__":
        sys.exit(main())

